ğŸ’³ Credit Card Fraud Detection System
ğŸ“Œ Overview

This project is an end-to-end machine learning system designed to detect fraudulent credit card transactions in real time.
It addresses extreme class imbalance (0.17% fraud) and prioritizes recall to minimize financial losses caused by undetected fraud.

The system includes:

Model training & evaluation

Real-time prediction API

Interactive dashboard

Explainable AI (SHAP)

ğŸš€ Features

Handles highly imbalanced data using SMOTE

Trained with XGBoost for high recall and ROC-AUC

FastAPI backend for real-time inference

Streamlit dashboard for interactive predictions

SHAP explainability for model transparency

Clean separation of experimentation and production code

ğŸ§  Tech Stack

Language: Python

Data Processing: Pandas, NumPy

Machine Learning: Scikit-learn, XGBoost, Imbalanced-learn

Explainability: SHAP

Backend API: FastAPI

Frontend: Streamlit

Version Control: Git & GitHub

ğŸ“Š Dataset

Source: Kaggle â€“ Credit Card Fraud Detection Dataset

Total Records: 284,807

Fraud Transactions: 492 (0.17%)

Features:

V1â€“V28: PCA-transformed features (confidentiality preserved)

Time: Seconds elapsed between transactions

Amount: Transaction amount

Class: 0 = Legitimate, 1 = Fraud

Due to confidentiality constraints, all sensitive features are PCA-transformed, which is common in financial datasets.

Folder Structure-
## ğŸ—ï¸ Project Structure

- [`api/`](api/) â€“ FastAPI backend
- [`app/`](app/) â€“ Streamlit dashboard
- [`src/`](src/) â€“ ML pipeline
- [`notebooks/`](notebooks/) â€“ EDA & experiments
- [`models/`](models/) â€“ Model artifacts (gitignored)
- [`data/`](data/) â€“ Dataset files (gitignored)



ğŸ“ˆ Model Performance

Recall (Fraud): ~95%

ROC-AUC: ~0.98

Focus Metric: Recall (to reduce false negatives)

Accuracy is misleading in highly imbalanced datasets; recall is prioritized to catch fraudulent transactions effectively.

ğŸ” Explainable AI (XAI)

The system integrates SHAP (SHapley Additive exPlanations) to interpret model predictions.

Explainability includes:

Global feature importance (overall fraud drivers)

Local explanations for individual transactions

Interactive explanations available in the Streamlit dashboard

This improves trust, transparency, and auditability in financial decision-making systems.

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

2ï¸âƒ£ Train the Model
python -m src.train

3ï¸âƒ£ Evaluate the Model
python -m src.evaluate

4ï¸âƒ£ Run Explainability (SHAP)
python -m src.explain

5ï¸âƒ£ Start FastAPI Backend
uvicorn api.main:app --reload


Open Swagger UI:

http://127.0.0.1:8000/docs

6ï¸âƒ£ Launch Streamlit Dashboard
streamlit run app/streamlit_app.py

ğŸŒ Live Demo

A public Streamlit application is deployed for real-time fraud prediction and explainability.
(Link added once active)
ğŸ“Œ Key Learnings

Handling extreme class imbalance is critical in fraud detection

Recall is more important than accuracy in high-risk domains

Explainability is essential for trust in ML systems

End-to-end deployment adds real-world value to ML projects

ğŸ§¾ Resume Summary

Built an end-to-end credit card fraud detection system using XGBoost and SMOTE, achieving ~95% recall. Deployed real-time predictions with FastAPI, built an interactive Streamlit dashboard, and integrated SHAP-based explainability for transparent decision-making.

ğŸ‘¤ Author

Giriprasath K
B.E. Computer Science Engineering (AI & ML)
